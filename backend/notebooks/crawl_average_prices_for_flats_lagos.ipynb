{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Tag\n",
    "import requests\n",
    "from markdownify import markdownify as md\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://nigeriapropertycentre.com/market-trends/average-prices/for-rent/flats-apartments/lagos'\n",
    "path = '../data_fetched/prices'\n",
    "delay = 10 # seconds\n",
    "bs_parser = 'html.parser'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            print(f\"failed to fetch response from {url} with status code {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"failed to fetch response from {url} with error {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_table(html_content):\n",
    "#     data = {}\n",
    "#     soup = BeautifulSoup(html_content, bs_parser)\n",
    "\n",
    "#     # Extract the title\n",
    "#     title = soup.find('h1', class_='page-title text-center')\n",
    "#     if title:\n",
    "#         title = title.get_text(strip=True)\n",
    "#     else:\n",
    "#         title = 'No title found'\n",
    "#     data['title'] = title\n",
    "\n",
    "#     # Extract the table\n",
    "#     table_section = soup.find('table', class_='google-visualization-table-table')\n",
    "#     if isinstance(table_section, Tag):\n",
    "#         table = table_section.find_all('tr', class_='google-visualization-table-tr-even')\n",
    "#     else:\n",
    "#         table = []\n",
    "#     data['table'] = table\n",
    "\n",
    "#     return data\n",
    "\n",
    "\n",
    "def extract_table(html_content):\n",
    "    data = {}\n",
    "    soup = BeautifulSoup(html_content, bs_parser)\n",
    "\n",
    "    # Extract the title\n",
    "    title_tag = soup.find('h1', class_='page-title text-center')\n",
    "    if title_tag:\n",
    "        title = title_tag.get_text(strip=True)\n",
    "    else:\n",
    "        title = 'No title found'\n",
    "    data['title'] = title\n",
    "\n",
    "    # Extract the table\n",
    "    table_section = soup.find('table', class_='google-visualization-table-table')\n",
    "    table_data = []\n",
    "\n",
    "    if isinstance(table_section, Tag):\n",
    "        # Extract table headers\n",
    "        header_row = table_section.find('tr', class_='google-visualization-table-tr-head')\n",
    "        if isinstance(header_row, Tag):\n",
    "            headers = [th.get_text(strip=True) for th in header_row.find_all('th')]\n",
    "            table_data.append(headers)\n",
    "\n",
    "        # Extract table rows\n",
    "        rows = table_section.find_all('tr', class_='google-visualization-table-tr-even')\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            cols_data = [col.get_text(strip=True) for col in cols]\n",
    "            table_data.append(cols_data)\n",
    "    else:\n",
    "        table_data = []\n",
    "\n",
    "    data['table'] = table_data\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_json(data):\n",
    "#     json_data = json.dumps(data, indent=4)\n",
    "#     return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, filename):\n",
    "    filename = filename.strip().replace(' ', '_')\n",
    "    with open(os.path.join(path, f'{filename}.json'), 'w') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Price of Flats for Rent in Lagos has been saved to ../data_fetched/prices\n",
      "Extracted data: {'title': 'Average Price of Flats for Rent in Lagos', 'table': [['Area', 'Average\\nPrice', 'Max. Property\\nPrice', 'Min. Property\\nPrice', 'Total Property\\nCount', 'New Property\\nAdded'], ['Eko Atlantic City', '₦42,730,000', '₦500,000,000', '₦3,000,000', '22', '5'], ['Ikoyi', '₦17,870,000', '₦10,000,000,000', '₦275,000', '3,560', '593'], ['Victoria Island (VI)', '₦8,840,000', '₦14,000,000,000', '₦450,000', '2,898', '474'], ['Lekki', '₦4,490,000', '₦8,500,000,000', '₦65,000', '16,982', '3,398'], ['Ikeja', '₦2,810,000', '₦3,000,000,000', '₦180,000', '1,646', '349'], ['Magodo', '₦2,700,000', '₦10,000,000', '₦400,000', '981', '206'], ['Gbagada', '₦2,670,000', '₦75,000,000', '₦70,000', '931', '199'], ['Maryland', '₦2,670,000', '₦45,000,000', '₦250,000', '321', '72'], ['Surulere', '₦2,350,000', '₦325,000,000', '₦300,000', '877', '133'], ['Ilupeju', '₦2,300,000', '₦6,000,000', '₦600,000', '98', '24'], ['Amuwo Odofin', '₦2,180,000', '₦6,000,000', '₦700,000', '44', '2'], ['Ogudu', '₦1,980,000', '₦10,000,000', '₦400,000', '444', '68'], ['Isheri', '₦1,910,000', '₦4,500,000', '₦700,000', '16', '6'], ['Yaba', '₦1,910,000', '₦70,000,000', '₦60,000', '1,159', '174'], ['Oke-Odo', '₦1,870,000', '₦3,000,000', '₦600,000', '3', '0'], ['Isheri North', '₦1,820,000', '₦125,000,000', '₦450,000', '140', '37'], ['Ijesha', '₦1,700,000', '₦1,700,000', '₦1,700,000', '1', '0'], ['Apapa', '₦1,650,000', '₦3,000,000', '₦1,200,000', '4', '1'], ['Ojota', '₦1,650,000', '₦3,000,000', '₦450,000', '22', '3'], ['Lagos Island', '₦1,600,000', '₦7,000,000', '₦500,000', '7', '1'], ['Isolo', '₦1,450,000', '₦5,000,000', '₦400,000', '246', '38'], ['Ajah', '₦1,450,000', '₦3,300,000,000', '₦60,000', '6,932', '1,268'], ['Ojodu', '₦1,430,000', '₦10,000,000', '₦350,000', '212', '35'], ['Shomolu', '₦1,410,000', '₦850,000,000', '₦150,000', '440', '81'], ['Oshodi', '₦1,370,000', '₦3,000,000', '₦700,000', '26', '7'], ['Ketu', '₦1,340,000', '₦4,000,000', '₦106,000', '383', '64'], ['Alimosho', '₦1,270,000', '₦3,000,000', '₦300,000', '108', '21'], ['Idimu', '₦1,180,000', '₦1,300,000', '₦800,000', '5', '0'], ['Mushin', '₦1,170,000', '₦1,800,000', '₦500,000', '12', '2'], ['Ejigbo', '₦1,150,000', '₦2,500,000', '₦250,000', '5', '2'], ['Egbe', '₦950,000', '₦2,250,000', '₦700,000', '4', '1'], ['Agege', '₦920,000', '₦4,000,000', '₦80,000', '233', '40'], ['Ifako-Ijaiye', '₦880,000', '₦2,500,000', '₦250,000', '29', '4'], ['Ibeju Lekki', '₦880,000', '₦48,000,000', '₦80,000', '921', '110'], ['Ijaiye', '₦840,000', '₦1,300,000', '₦600,000', '4', '0'], ['Kosofe', '₦820,000', '₦3,500,000', '₦120,000', '73', '16'], ['Ikotun', '₦680,000', '₦7,000,000', '₦300,000', '52', '22'], ['Agbara-Igbesa', '₦680,000', '₦4,500,000', '₦400,000', '20', '4'], ['Ibeju', '₦650,000', '₦1,100,000', '₦350,000', '5', '0'], ['Ipaja', '₦640,000', '₦2,000,000', '₦120,000', '249', '23'], ['Ojo', '₦600,000', '₦4,000,000', '₦250,000', '25', '7'], ['Ikorodu', '₦540,000', '₦2,500,000', '₦96,000', '321', '66'], ['Ayobo', '₦450,000', '₦1,400,000', '₦150,000', '56', '12'], ['Epe', '₦320,000', '₦1,000,000', '₦240,000', '9', '2'], ['Iganmu', '₦300,000', '₦300,000', '₦300,000', '1', '1']]}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    html_content = fetch_page(base_url)\n",
    "    if html_content:\n",
    "        extracted_data = extract_table(html_content)\n",
    "        filename = extracted_data['title']\n",
    "        # json_data = convert_to_json(extracted_data)\n",
    "        save_json(extracted_data, filename)\n",
    "        print(f'{filename} has been saved to {path}')\n",
    "        print(f'Extracted data: {extracted_data}')\n",
    "    else:\n",
    "        print(f\"Failed to fetch {base_url}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
